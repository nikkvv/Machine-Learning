{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a classification model\n",
    "\n",
    "*From the video series: [Introduction to machine learning with scikit-learn](https://github.com/justmarkham/scikit-learn-videos)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "- What is the purpose of **model evaluation**, and what are some common evaluation procedures?\n",
    "- What is the usage of **classification accuracy**, and what are its limitations?\n",
    "- How does a **confusion matrix** describe the performance of a classifier?\n",
    "- What **metrics** can be computed from a confusion matrix?\n",
    "- How can you adjust classifier performance by **changing the classification threshold**?\n",
    "- What is the purpose of an **ROC curve**?\n",
    "- How does **Area Under the Curve (AUC)** differ from classification accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of model evaluation\n",
    "\n",
    "- Need a way to choose between models: different model types, tuning parameters, and features\n",
    "- Use a **model evaluation procedure** to estimate how well a model will generalize to out-of-sample data\n",
    "- Requires a **model evaluation metric** to quantify the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation procedures\n",
    "\n",
    "1. **Training and testing on the same data**\n",
    "    - Rewards overly complex models that \"overfit\" the training data and won't necessarily generalize\n",
    "2. **Train/test split**\n",
    "    - Split the dataset into two pieces, so that the model can be trained and tested on different data\n",
    "    - Better estimate of out-of-sample performance, but still a \"high variance\" estimate\n",
    "    - Useful due to its speed, simplicity, and flexibility\n",
    "3. **K-fold cross-validation**\n",
    "    - Systematically create \"K\" train/test splits and average the results together\n",
    "    - Even better estimate of out-of-sample performance\n",
    "    - Runs \"K\" times slower than train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation metrics\n",
    "\n",
    "- **Regression problems:** Mean Absolute Error, Mean Squared Error, Root Mean Squared Error\n",
    "- **Classification problems:** Classification accuracy\n",
    "\n",
    "There are many other important metrics for classification problems, and those metrics are the topic of this session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification accuracy\n",
    "\n",
    "[Pima Indian Diabetes dataset](https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes) from the UCI Machine Learning Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the data into a Pandas DataFrame\n",
    "import pandas as pd\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data'\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "pima = pd.read_csv(url, header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  bp  skin  insulin   bmi  pedigree  age  label\n",
       "0         6      148  72    35        0  33.6     0.627   50      1\n",
       "1         1       85  66    29        0  26.6     0.351   31      0\n",
       "2         8      183  64     0        0  23.3     0.672   32      1\n",
       "3         1       89  66    23       94  28.1     0.167   21      0\n",
       "4         0      137  40    35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 rows of data\n",
    "pima.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each row represents one patient.\n",
    "- `label` column indicates whether patient has diabetes or not (1 = yes, 0 = no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are defining the classification problem as follows :-\n",
    "\n",
    "**Question:** Can we predict the diabetes status of a patient given their health measurements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age']\n",
    "X = pima[feature_cols]\n",
    "y = pima.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Honey\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for the testing set\n",
    "y_pred_class = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification accuracy:** percentage of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.692708333333\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above accuracy is pretty good.\n",
    "- **However**, anytime you use classification accuracy as your evaluation metric, it is important to compare it with Null Accuracy, which is the accuracy that can be achieved by always predicting the most frequent class in testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null accuracy:** accuracy that could be achieved by always predicting the most frequent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution of the testing set (using a Pandas Series method)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3229166666666667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of ones\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the percentage of zeros\n",
    "1 - y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy (for binary classification problems coded as 0/1)\n",
    "max(y_test.mean(), 1 - y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.677083\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy (for multi-class classification problems)\n",
    "y_test.value_counts().head(1) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ~68% is the Null Accuracy for this problem\n",
    "- In other words, a dumb model that always predict that a patient does not have diabetes will be right 68% of the time.\n",
    "- This is obviously not a useful model, but it provides a baseline against which we might want to measure our logistic regression model.\n",
    "- When we compare the Null Accuracy of 68% with model accuracy of 69%, suddenly our model does not look very good.\n",
    "- This demonstrates one weakness of classification accuracy as a model evaluation metric, that the **classification accuracy does not tell us anything about the underlying distribution of the testing set**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the **true** and **predicted** response values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0]\n",
      "Pred: [0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "from __future__ import print_function\n",
    "print('True:', y_test.values[0:25])\n",
    "print('Pred:', y_pred_class[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the above case we can see that when the true response value is 0, the model almost always predict a 0. Whereas when the true response value is a 1, the model rarely predicts a 1.\n",
    "- In other words, the model is usually making a certain type of errors but not others, but we may never know that simply by examining the accuracy.\n",
    "- This is another weakness of classification accuracy.\n",
    "- This weakness is overcome using **Confusion matrix** discussed next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Classification accuracy is the **easiest classification metric to understand**\n",
    "- But, it does not tell you the **underlying distribution** of response values\n",
    "- And, it does not tell you what **\"types\" of errors** your classifier is making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "\n",
    "Table that describes the performance of a classification model\n",
    "\n",
    "- The **confusion_matrix()** function is also available in the **metrics** module.\n",
    "- **NOTE :- ** when using the confusion matrix always pass the true response as the first argument and the predicted response as the second argument. It's a good habit to adapt regardless of whether the order matters(eg. accuracy), to always pass the true value as first argument and predicted value as second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 47  15]]\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted values\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Small confusion matrix](images/09_confusion_matrix_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Every observation in the testing set is represented in **exactly one box**\n",
    "- It's a 2x2 matrix because there are **2 response classes**\n",
    "- The format shown here is **not** universal, as sometimes the position of true and predicted values are reversed so pay attention to the format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Its conventional to denote the class denoted by 1 as the positive class and class denoted by 0 as a negative class.\n",
    "- That is why correctly predicting a 1 value is **True Positive** and correctly predicting a 0 is a **True Negative**.\n",
    "- **False Positives** are known in some fields as **Type 1 errors**\n",
    "- **False Negatives** are known in some fields as **Type 2 errors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic terminology**\n",
    "\n",
    "- **True Positives (TP):** we *correctly* predicted that they *do* have diabetes\n",
    "- **True Negatives (TN):** we *correctly* predicted that they *don't* have diabetes\n",
    "- **False Positives (FP):** we *incorrectly* predicted that they *do* have diabetes (a \"Type I error\")\n",
    "- **False Negatives (FN):** we *incorrectly* predicted that they *don't* have diabetes (a \"Type II error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0]\n",
      "Pred: [0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "print('True:', y_test.values[0:25])\n",
    "print('Pred:', y_pred_class[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Large confusion matrix](images/09_confusion_matrix_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics computed from a confusion matrix\n",
    "\n",
    "- The confusion matrix is useful for you to understand the performance of your classifier.\n",
    "- But, Confusion matrix is not a model evaluation metric and so we can't simply tell scikit-learn to choose the model with best confusion matrix.\n",
    "- However, there are many metrics that can be calculated from the confusion matrix and those can be directly used to choose between models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Accuracy:** Overall, how often is the classifier correct?\n",
    "\n",
    "$$Classification\\ Accuracy = \\frac {TP+TN} {total\\ observations}$$\n",
    "\n",
    "It can also be calculated from **sklearn** using **metrics** module's **accuracy_score()** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.692708333333\n",
      "0.692708333333\n"
     ]
    }
   ],
   "source": [
    "print((TP + TN) / float(TP + TN + FP + FN))         # Converting to float to do true division instead of integer division\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Error:** Overall, how often is the classifier incorrect?\n",
    "\n",
    "- Also known as \"**Misclassification Rate**\"\n",
    "\n",
    "$$Classification\\ Error = \\frac {FP+FN} {total\\ observations}$$\n",
    "\n",
    "i.e (1 - Classification Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.307291666667\n",
      "0.307291666667\n"
     ]
    }
   ],
   "source": [
    "print((FP + FN) / float(TP + TN + FP + FN))\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sensitivity:** When the actual value is positive, how often is the prediction correct?\n",
    "\n",
    "- How \"**sensitive**\" is the classifier to detecting positive instances?\n",
    "- Also known as \"**True Positive Rate**\" or \"**Recall**\"\n",
    "- Sensitivity is something that we want to maximize.\n",
    "\n",
    "$$ Sensitivity = \\frac {TP} {TP+FN} $$\n",
    "\n",
    "**sklearn.metrics** module also provides a method **recall_score()** to calculate the sensitivity or recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.241935483871\n",
      "0.241935483871\n"
     ]
    }
   ],
   "source": [
    "print(TP / float(TP + FN))\n",
    "print(metrics.recall_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity:** When the actual value is negative, how often is the prediction correct?\n",
    "\n",
    "- How \"specific\" (or \"selective\") is the classifier in predicting positive instances?\n",
    "- Similar to sensitivity, Specificity is also something we want to maximize\n",
    "- There is no inbuilt metric function in sklearn to calculate specificity\n",
    "\n",
    "$$ Specificity = \\frac {TN} {TN + FP}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907692307692\n"
     ]
    }
   ],
   "source": [
    "print(TN / float(TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Positive Rate:** When the actual value is negative, how often is the prediction incorrect?\n",
    "\n",
    "$$ False\\ Positive\\ Rate = \\frac {FP} {TN + FP}$$\n",
    "\n",
    "or simply (1 - Specificity)\n",
    "\n",
    "We want this metric to be minimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0923076923077\n"
     ]
    }
   ],
   "source": [
    "print(FP / float(TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision:** When a positive value is predicted, how often is the prediction correct?\n",
    "\n",
    "- How \"precise\" is the classifier when predicting positive instances?\n",
    "- **sklearn.metrics** module has a function **precision_score()** to calculate precision\n",
    "\n",
    "$$ Precision = \\frac {TP} {TP + FP}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.555555555556\n",
      "0.555555555556\n"
     ]
    }
   ],
   "source": [
    "print(TP / float(TP + FP))\n",
    "print(metrics.precision_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :- **Many other metrics can be computed from confusion matrix such as the **F1 score**, **Matthews correlation coefficient**, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Advisable to always compute the confusion matrix for your classifier.\n",
    "- Confusion matrix gives you a **more complete picture** of how your classifier is performing\n",
    "- Also allows you to compute various **classification metrics**, and these metrics can guide your model selection\n",
    "- However we can't optimize the model for each of the metric, so we have to choose between them.\n",
    "\n",
    "**Which metrics should you focus on?**\n",
    "\n",
    "- Choice of metric depends on your **business objective**. Check below two examples :-\n",
    "\n",
    "**Spam filter** (positive class is \"spam\"): Optimize for **precision or specificity** because false negatives (spam goes to the inbox) are more acceptable than false positives (non-spam is caught by the spam filter)\n",
    "\n",
    "**Fraudulent transaction detector** (positive class is \"fraud\"): Optimize for **sensitivity** because false positives (normal transactions that are flagged as possible fraud) are more acceptable than false negatives (fraudulent transactions that are not detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting the classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted responses\n",
    "logreg.predict(X_test)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a similar method called **predict_proba()** gives the predicted probabilities of class membership\n",
    "- Each row is one observation and each column represents a particular class, and shows the probability of observation to belong to that class.\n",
    "- The **predict()** method first predicts the probabilities for each class for any observation and then selects the class with the highest probability as the class for that observation.\n",
    "- For a binary problem like this one, another way of thinking about this is that there is a classification threshold of 0.5. Only if that threshold is exceeded then class 1 is predicted, otherwise class 0 is predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63247571,  0.36752429],\n",
       "       [ 0.71643656,  0.28356344],\n",
       "       [ 0.71104114,  0.28895886],\n",
       "       [ 0.5858938 ,  0.4141062 ],\n",
       "       [ 0.84103973,  0.15896027],\n",
       "       [ 0.82934844,  0.17065156],\n",
       "       [ 0.50110974,  0.49889026],\n",
       "       [ 0.48658459,  0.51341541],\n",
       "       [ 0.72321388,  0.27678612],\n",
       "       [ 0.32810562,  0.67189438]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted probabilities of class membership\n",
    "logreg.predict_proba(X_test)[0:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.36752429,  0.28356344,  0.28895886,  0.4141062 ,  0.15896027,\n",
       "        0.17065156,  0.49889026,  0.51341541,  0.27678612,  0.67189438])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted probabilities for class 1\n",
    "logreg.predict_proba(X_test)[0:10, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store the predicted probabilities for class 1\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plotting a histogram of these probabilities can help us see the effect of changing the classification threshold on performance of the model.\n",
    "- The histogram shows the distribution of a numerical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allow plots to appear in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xc62df10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEiCAYAAAA8ij+xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxB6jDzz0FyMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc615b30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram of predicted probabilities\n",
    "plt.hist(y_pred_prob, bins=8)\n",
    "plt.xlim(0, 1)\n",
    "plt.title('Histogram of predicted probabilities')\n",
    "plt.xlabel('Predicted probability of diabetes')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see from the above histogram that only a small portion of observations from testing set are predicted as positive (i.e. with probability more than 0.5)\n",
    "- We can adjust both the sensitivity and specificity of a classifier simply by adjusting the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decrease the threshold** for predicting diabetes in order to **increase the sensitivity** of the classifier\n",
    "\n",
    "- This increases sensitivity because the classifier is now more sensitive to positive instances, because now more instances will be classified as positive.\n",
    "- Eg. A **Metal detector** is essentially a classifier which predicts metal and a threshold is set so that large metal objects set off the detector but tiny ones do not. To increase the sensitivity of the metal detector, you have to **decrease** the threshold (i.e. the amount of metal that is required to set it off), and thus it is now more sensitive to metal and will predict yes more often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **sklearn.preprocessing** module has a **binarize()** function that can be given the threshold for converting all values above threshold to 1 and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict diabetes if the predicted probability is greater than 0.3\n",
    "from sklearn.preprocessing import binarize\n",
    "y_pred_class = binarize([y_pred_prob], 0.3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.36752429,  0.28356344,  0.28895886,  0.4141062 ,  0.15896027,\n",
       "        0.17065156,  0.49889026,  0.51341541,  0.27678612,  0.67189438])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted probabilities\n",
    "y_pred_prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  1.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 10 predicted classes with the lower threshold\n",
    "y_pred_class[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 47  15]]\n"
     ]
    }
   ],
   "source": [
    "# previous confusion matrix (default threshold of 0.5)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[80 50]\n",
      " [16 46]]\n"
     ]
    }
   ],
   "source": [
    "# new confusion matrix (threshold of 0.3)\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7419354838709677\n"
     ]
    }
   ],
   "source": [
    "# sensitivity has increased (used to be 0.24)\n",
    "print(46 / float(46 + 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "# specificity has decreased (used to be 0.91)\n",
    "print(80 / float(80 + 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "- **Threshold of 0.5** is used by default (for binary problems) to convert predicted probabilities into class predictions\n",
    "- Threshold can be **adjusted** to increase sensitivity or specificity depending on your business objective.\n",
    "- Sensitivity and specificity have an **inverse relationship**\n",
    "- **Note :-** Adjusting the threshold is one of the last step in the model building process. The majority of the time should be focussed on building better models and then selecting the best possible model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves and Area Under the Curve (AUC)\n",
    "\n",
    "**Question:** Wouldn't it be nice if we could see how sensitivity and specificity are affected by various thresholds, without actually changing the threshold?\n",
    "\n",
    "**Answer:** Plot the ROC curve!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The ROC curve is a plot of the True Positive Rate (tpr) on the Y-axis against the False Positive Rate (fpr) on the X-axis for all possible classification thresholds from 0 to 1.\n",
    "- So, Y-axis is Sensitivity and X-axis is (1-Specificity)\n",
    "- **sklearn.metrics** module provides the method **roc_curve()**\n",
    "- We pass it the true values for the testing set and the predicted probabilities for class 1 for each observation.\n",
    "    - **Note -** It is critically important that you use predicted probabilities and not the predicted class.\n",
    "- It returns three objects - **fpr**, **tpr** and **thresholds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEiCAYAAAA1YZ/LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOWcuZmbWcv8fIhZfldZE8F0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc62dc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for diabetes classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The optimal ROC curve would meet the upper left corner of the plot, since that would represent a classifier with high sensitivity and high specificity.\n",
    "- ROC curve can help you to **choose a threshold** that balances sensitivity and specificity in a way that makes sense for your particular context\n",
    "- You can't actually **see the thresholds** used to generate the curve on the ROC curve itself\n",
    "    - Below is a small helper function that allows you to pass-in a threshold value and see the sensitivity and specificity at that threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that accepts a threshold and prints sensitivity and specificity\n",
    "def evaluate_threshold(threshold):\n",
    "    print('Sensitivity:', tpr[thresholds > threshold][-1])\n",
    "    print('Specificity:', 1 - fpr[thresholds > threshold][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.241935483871\n",
      "Specificity: 0.907692307692\n"
     ]
    }
   ],
   "source": [
    "evaluate_threshold(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.725806451613\n",
      "Specificity: 0.615384615385\n"
     ]
    }
   ],
   "source": [
    "evaluate_threshold(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Given a particular point on the ROC curve it would a simple trial-and-error process to locate the threshold that produced that point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC is the **percentage** of the ROC plot that is **underneath the curve**:\n",
    "\n",
    "Because an ideal classifier hugs the upper left corner of the plot, a higher AUC value indicates a better overall classifier.\n",
    "- Best possible AUC for any classifier is **1.0**\n",
    "- **sklearn.metrics** module has function **roc_auc_score()** to calculate the AUC for the ROC curve\n",
    "    - Once again we pass in the true response values as first argument and the predicted probabilities as second argument (not the predicted classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.724565756824\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "print(metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AUC is often used as a **single number summary** of classifier performance as an alternative to classification accuracy.\n",
    "- If you randomly chose one positive and one negative observation, AUC represents the likelihood that your classifier will assign a **higher predicted probability** to the positive observation.\n",
    "- AUC is useful even when there is **high class imbalance** (unlike classification accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Because AUC is a useful metric for choosing between models, it is available as a scoring function for **cross_val_score()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73782336182336183"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate cross-validated AUC\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(logreg, X, y, cv=10, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix advantages:**\n",
    "\n",
    "- Allows you to calculate a **variety of metrics**\n",
    "- Useful for **multi-class problems** (more than two response classes)\n",
    "\n",
    "**ROC/AUC advantages:**\n",
    "\n",
    "- Does not require you to **set a classification threshold** unlike the confusion matrix.\n",
    "- Still useful when there is **high class imbalance**\n",
    "- However, they are less interpretable than confusion matrix for multi-class problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Resources\n",
    "\n",
    "- Blog post: [Simple guide to confusion matrix terminology](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/) by me\n",
    "- Videos: [Intuitive sensitivity and specificity](https://www.youtube.com/watch?v=U4_3fditnWg) (9 minutes) and [The tradeoff between sensitivity and specificity](https://www.youtube.com/watch?v=vtYDyGGeQyo) (13 minutes) by Rahul Patwari\n",
    "- Notebook: [How to calculate \"expected value\"](https://github.com/podopie/DAT18NYC/blob/master/classes/13-expected_value_cost_benefit_analysis.ipynb) from a confusion matrix by treating it as a cost-benefit matrix (by Ed Podojil)\n",
    "- Graphic: How [classification threshold](https://media.amazonwebservices.com/blog/2015/ml_adjust_model_1.png) affects different evaluation metrics (from a [blog post](https://aws.amazon.com/blogs/aws/amazon-machine-learning-make-data-driven-decisions-at-scale/) about Amazon Machine Learning)\n",
    "\n",
    "\n",
    "## ROC and AUC Resources\n",
    "\n",
    "- Lesson notes: [ROC Curves](http://ebp.uga.edu/courses/Chapter%204%20-%20Diagnosis%20I/8%20-%20ROC%20curves.html) (from the University of Georgia)\n",
    "- Video: [ROC Curves and Area Under the Curve](https://www.youtube.com/watch?v=OAl6eAyP-yo) (14 minutes) by me, including [transcript and screenshots](http://www.dataschool.io/roc-curves-and-auc-explained/) and a [visualization](http://www.navan.name/roc/)\n",
    "- Video: [ROC Curves](https://www.youtube.com/watch?v=21Igj5Pr6u4) (12 minutes) by Rahul Patwari\n",
    "- Paper: [An introduction to ROC analysis](http://people.inf.elte.hu/kiss/13dwhdm/roc.pdf) by Tom Fawcett\n",
    "- Usage examples: [Comparing different feature sets](http://research.microsoft.com/pubs/205472/aisec10-leontjeva.pdf) for detecting fraudulent Skype users, and [comparing different classifiers](http://www.cse.ust.hk/nevinZhangGroup/readings/yi/Bradley_PR97.pdf) on a number of popular datasets\n",
    "\n",
    "## Other Resources\n",
    "\n",
    "- scikit-learn documentation: [Model evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- Guide: [Comparing model evaluation procedures and metrics](https://github.com/justmarkham/DAT8/blob/master/other/model_evaluation_comparison.md) by me\n",
    "- Video: [Counterfactual evaluation of machine learning models](https://www.youtube.com/watch?v=QWCSxAKR-h0) (45 minutes) about how Stripe evaluates its fraud detection model, including [slides](http://www.slideshare.net/MichaelManapat/counterfactual-evaluation-of-machine-learning-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments or Questions?\n",
    "\n",
    "- Email: <kevin@dataschool.io>\n",
    "- Website: http://dataschool.io\n",
    "- Twitter: [@justmarkham](https://twitter.com/justmarkham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width: 90%;\n",
       "/*        margin-left:auto;*/\n",
       "/*        margin-right:auto;*/\n",
       "    }\n",
       "    ul {\n",
       "        line-height: 145%;\n",
       "        font-size: 90%;\n",
       "    }\n",
       "    li {\n",
       "        margin-bottom: 1em;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top: 12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 130%;\n",
       "        width: 90%;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "/*    .prompt{\n",
       "        display: None;\n",
       "    }*/\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 16pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
