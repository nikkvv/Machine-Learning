{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning with Scikit-learn [Data School Series]\n",
    "- https://www.youtube.com/watch?v=elojMnjn4kk&list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&index=1\n",
    "- https://github.com/justmarkham/scikit-learn-videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heading \n",
    "\n",
    "Regular Text\n",
    "\n",
    "** Bold Text **\n",
    "\n",
    "- bullet 1\n",
    "- bullet 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = list(range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 5, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "a.append(5)\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"300\"\n",
       "            height=\"200\"\n",
       "            src=\"http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ab6d90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iris dataset for determining Iris Flower species\n",
    "from IPython.display import IFrame\n",
    "IFrame('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', width=300, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import dataset loading function from \"sklearn.datasets\" module\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset into a variable\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.datasets.base.Bunch"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bunch - Scikit Learn's special object type for storing datasets and their attributes\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.4  3.7  1.5  0.2]\n",
      " [ 4.8  3.4  1.6  0.2]\n",
      " [ 4.8  3.   1.4  0.1]\n",
      " [ 4.3  3.   1.1  0.1]\n",
      " [ 5.8  4.   1.2  0.2]\n",
      " [ 5.7  4.4  1.5  0.4]\n",
      " [ 5.4  3.9  1.3  0.4]\n",
      " [ 5.1  3.5  1.4  0.3]\n",
      " [ 5.7  3.8  1.7  0.3]\n",
      " [ 5.1  3.8  1.5  0.3]\n",
      " [ 5.4  3.4  1.7  0.2]\n",
      " [ 5.1  3.7  1.5  0.4]\n",
      " [ 4.6  3.6  1.   0.2]\n",
      " [ 5.1  3.3  1.7  0.5]\n",
      " [ 4.8  3.4  1.9  0.2]\n",
      " [ 5.   3.   1.6  0.2]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 5.2  3.5  1.5  0.2]\n",
      " [ 5.2  3.4  1.4  0.2]\n",
      " [ 4.7  3.2  1.6  0.2]\n",
      " [ 4.8  3.1  1.6  0.2]\n",
      " [ 5.4  3.4  1.5  0.4]\n",
      " [ 5.2  4.1  1.5  0.1]\n",
      " [ 5.5  4.2  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.   3.2  1.2  0.2]\n",
      " [ 5.5  3.5  1.3  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 4.4  3.   1.3  0.2]\n",
      " [ 5.1  3.4  1.5  0.2]\n",
      " [ 5.   3.5  1.3  0.3]\n",
      " [ 4.5  2.3  1.3  0.3]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 5.1  3.8  1.9  0.4]\n",
      " [ 4.8  3.   1.4  0.3]\n",
      " [ 5.1  3.8  1.6  0.2]\n",
      " [ 4.6  3.2  1.4  0.2]\n",
      " [ 5.3  3.7  1.5  0.2]\n",
      " [ 5.   3.3  1.4  0.2]\n",
      " [ 7.   3.2  4.7  1.4]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 6.5  2.8  4.6  1.5]\n",
      " [ 5.7  2.8  4.5  1.3]\n",
      " [ 6.3  3.3  4.7  1.6]\n",
      " [ 4.9  2.4  3.3  1. ]\n",
      " [ 6.6  2.9  4.6  1.3]\n",
      " [ 5.2  2.7  3.9  1.4]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 5.9  3.   4.2  1.5]\n",
      " [ 6.   2.2  4.   1. ]\n",
      " [ 6.1  2.9  4.7  1.4]\n",
      " [ 5.6  2.9  3.6  1.3]\n",
      " [ 6.7  3.1  4.4  1.4]\n",
      " [ 5.6  3.   4.5  1.5]\n",
      " [ 5.8  2.7  4.1  1. ]\n",
      " [ 6.2  2.2  4.5  1.5]\n",
      " [ 5.6  2.5  3.9  1.1]\n",
      " [ 5.9  3.2  4.8  1.8]\n",
      " [ 6.1  2.8  4.   1.3]\n",
      " [ 6.3  2.5  4.9  1.5]\n",
      " [ 6.1  2.8  4.7  1.2]\n",
      " [ 6.4  2.9  4.3  1.3]\n",
      " [ 6.6  3.   4.4  1.4]\n",
      " [ 6.8  2.8  4.8  1.4]\n",
      " [ 6.7  3.   5.   1.7]\n",
      " [ 6.   2.9  4.5  1.5]\n",
      " [ 5.7  2.6  3.5  1. ]\n",
      " [ 5.5  2.4  3.8  1.1]\n",
      " [ 5.5  2.4  3.7  1. ]\n",
      " [ 5.8  2.7  3.9  1.2]\n",
      " [ 6.   2.7  5.1  1.6]\n",
      " [ 5.4  3.   4.5  1.5]\n",
      " [ 6.   3.4  4.5  1.6]\n",
      " [ 6.7  3.1  4.7  1.5]\n",
      " [ 6.3  2.3  4.4  1.3]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 5.5  2.5  4.   1.3]\n",
      " [ 5.5  2.6  4.4  1.2]\n",
      " [ 6.1  3.   4.6  1.4]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 5.   2.3  3.3  1. ]\n",
      " [ 5.6  2.7  4.2  1.3]\n",
      " [ 5.7  3.   4.2  1.2]\n",
      " [ 5.7  2.9  4.2  1.3]\n",
      " [ 6.2  2.9  4.3  1.3]\n",
      " [ 5.1  2.5  3.   1.1]\n",
      " [ 5.7  2.8  4.1  1.3]\n",
      " [ 6.3  3.3  6.   2.5]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 6.5  3.   5.8  2.2]\n",
      " [ 7.6  3.   6.6  2.1]\n",
      " [ 4.9  2.5  4.5  1.7]\n",
      " [ 7.3  2.9  6.3  1.8]\n",
      " [ 6.7  2.5  5.8  1.8]\n",
      " [ 7.2  3.6  6.1  2.5]\n",
      " [ 6.5  3.2  5.1  2. ]\n",
      " [ 6.4  2.7  5.3  1.9]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 5.7  2.5  5.   2. ]\n",
      " [ 5.8  2.8  5.1  2.4]\n",
      " [ 6.4  3.2  5.3  2.3]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 7.7  3.8  6.7  2.2]\n",
      " [ 7.7  2.6  6.9  2.3]\n",
      " [ 6.   2.2  5.   1.5]\n",
      " [ 6.9  3.2  5.7  2.3]\n",
      " [ 5.6  2.8  4.9  2. ]\n",
      " [ 7.7  2.8  6.7  2. ]\n",
      " [ 6.3  2.7  4.9  1.8]\n",
      " [ 6.7  3.3  5.7  2.1]\n",
      " [ 7.2  3.2  6.   1.8]\n",
      " [ 6.2  2.8  4.8  1.8]\n",
      " [ 6.1  3.   4.9  1.8]\n",
      " [ 6.4  2.8  5.6  2.1]\n",
      " [ 7.2  3.   5.8  1.6]\n",
      " [ 7.4  2.8  6.1  1.9]\n",
      " [ 7.9  3.8  6.4  2. ]\n",
      " [ 6.4  2.8  5.6  2.2]\n",
      " [ 6.3  2.8  5.1  1.5]\n",
      " [ 6.1  2.6  5.6  1.4]\n",
      " [ 7.7  3.   6.1  2.3]\n",
      " [ 6.3  3.4  5.6  2.4]\n",
      " [ 6.4  3.1  5.5  1.8]\n",
      " [ 6.   3.   4.8  1.8]\n",
      " [ 6.9  3.1  5.4  2.1]\n",
      " [ 6.7  3.1  5.6  2.4]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.9  3.   5.1  1.8]]\n"
     ]
    }
   ],
   "source": [
    "# One of the Bunch's attribute is called data, which is the data for the features. Each row is one sample/observation.\n",
    "# Each column is a feature.\n",
    "print (iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# Attribute for the feature names for the 4 features\n",
    "print (iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Target/Response attribute, i.e the item we are going to predict\n",
    "print (iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# Target name attribute\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# Ensure that feature and response are in the form scikit learn expects.\n",
    "# 1) Features and response are separate objects\n",
    "# 2) Features and response should be numeric\n",
    "# 3) Features and response should be NumPy arrays\n",
    "# 4) Features and response should have specific shapes\n",
    "\n",
    "print (type(iris.data))\n",
    "print (type(iris.target))\n",
    "\n",
    "print (iris.data.shape)\n",
    "print (iris.target.shape)\n",
    "\n",
    "# Scikit-Learn convention is for the feature data to be stored in an object named 'X' and the target be stored in an object\n",
    "# named 'y'\n",
    "\n",
    "# Store feature matrix in \"X\" matrix\n",
    "X = iris.data\n",
    "\n",
    "# Store target/response vectoe in 'y' vector\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classification\n",
    "### K - Nearest Neighbour\n",
    "\n",
    "- Pick a value for K.\n",
    "- Search for the K observations in the training data that are \"nearest\" to the measurements of the unknown iris.\n",
    "- Use the most popular response value from the K nearest neighbors as the predicted response value for the unknown iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying KNN on iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn 4-step modeling pattern\n",
    "\n",
    "**Step 1:** Import the class you plan to use\n",
    "\n",
    "**Step 2:** \"Instantiate\" the \"estimator\"\n",
    "- \"Estimator\" is scikit-learn's term for model\n",
    "- \"Instantiate\" means \"make an instance of\"\n",
    "- Name of the object does not matter\n",
    "- Can specify tuning parameters (aka \"hyperparameters\") during this step\n",
    "- All parameters not specified are set to their defaults\n",
    "\n",
    "**Step 3:** Fit the model with data (aka \"model training\")\n",
    "- Model is learning the relationship between X and y\n",
    "- Occurs in-place\n",
    "\n",
    "**Step 4:** Predict the response for a new observation\n",
    "- New observations are called \"out-of-sample\" data\n",
    "- Uses the information it learned during the model training process\n",
    "- Returns a NumPy array\n",
    "- Can predict for multiple observations at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Step 2\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Step 3\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Step 4 - Arguments passed as list are automatically converted to numpy array\n",
    "knn.predict([[1,2,3,4], [3,4,2,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "- sklearn models have a consistent interface.\n",
    "- Code below is similar in structure to the one used in KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "logreg.predict([[1,2,3,4],[3,4,2,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "### Classification accuracy:\n",
    "- Proportion of correct predictions\n",
    "- Common evaluation metric for classification problems\n",
    "- Known as **training accuracy** when you train and test the model on the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy =  0.966666666667\n",
      "Logistic Regression Accuracy =  0.96\n"
     ]
    }
   ],
   "source": [
    "# Testing on the training data \n",
    "y_pred_knn = knn.predict(X)\n",
    "y_pred_logreg = logreg.predict(X)\n",
    "\n",
    "# Classification accuracy metric from sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Getting Training accuracy\n",
    "print (\"KNN Accuracy = \", accuracy_score(y, y_pred_knn))\n",
    "print (\"Logistic Regression Accuracy = \", accuracy_score(y, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with training and testing on the same data\n",
    "- Goal is to estimate likely performance of a model on out-of-sample data\n",
    "- But, maximizing training accuracy rewards overly complex models that won't necessarily generalize\n",
    "- Unnecessarily complex models overfit the training data\n",
    "- Example KNN model with K=1 will have 100% training accuracy and can be misleading. It will not generalize to unseen data.\n",
    "- Therefore training and testing on the same data is not the correct metric to choose a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split\n",
    "- Split the dataset into two pieces: a training set and a testing set.\n",
    "- Train the model on the training set.\n",
    "- Test the model on the testing set, and evaluate how well we did.\n",
    "- Model can be trained and tested on different data\n",
    "- Response values are known for the testing set, and thus predictions can be evaluated\n",
    "- **Testing accuracy** is a better estimate than training accuracy of out-of-sample performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use sklearn's method\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# The data is split into 60:40 split into training set and testing set\n",
    "# Fixing a random state will create the same split everytime, otherwise random splits are created.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(60, 4)\n",
      "(90,)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression testing accuracy =  0.95\n",
      "KNN with K=5 testing accuracy =  0.966666666667\n",
      "KNN with K=1 testing accuracy =  0.95\n"
     ]
    }
   ],
   "source": [
    "# Check testing accuracy for 3 models :-\n",
    "# 1) Logistic regression\n",
    "# 2) KNN with K=5\n",
    "# 3) KNN with K=1\n",
    "\n",
    "# 1) Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "print (\"Logistic Regression testing accuracy = \", accuracy_score(y_test, y_pred_logreg))\n",
    "\n",
    "# 2) KNN with K=5\n",
    "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_5.fit(X_train, y_train)\n",
    "y_pred_knn5 = knn_5.predict(X_test)\n",
    "print (\"KNN with K=5 testing accuracy = \", accuracy_score(y_test, y_pred_knn5))\n",
    "\n",
    "# 3) KNN with K=1\n",
    "knn_1 = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_1.fit(X_train, y_train)\n",
    "y_pred_knn1 = knn_1.predict(X_test)\n",
    "print (\"KNN with K=1 testing accuracy = \", accuracy_score(y_test, y_pred_knn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As per above accuracy readings we conclude that among the 3 models, KNN with K=5 is likely to be the best model to make\n",
    "# predictions on out-of-sample data\n",
    "\n",
    "# But we can look to find an even better value of K in the way shown below\n",
    "\n",
    "# Gather the scores for all the values of K from [1, 25]\n",
    "scores = []\n",
    "for i in range(1,26):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_knni = knn.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred_knni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xaf555f0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xaf33470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use plot to check the value of K with maximum accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# allows plots to appear within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(1,26), scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In general as the value of K increases, there appears to be a rise in the testing accuracy and then a fall.\n",
    "- This rise and fall is actually quite typical when examining the relationship between model complexity and testing accuracy\n",
    "- Testing accuracy penalises models that are too complex as well as models that are not complex enough.\n",
    "- We see the maximum testing accuracy when the model has the right amount of complexity\n",
    "- For KNN models, complexity is determined by the value of K (lower value = more complex)\n",
    "- **Once we have the best parameters for the model, train the model again with full data to make use of all the available supervised data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose K=11 as that's in the middle of the range of highest testing accuracy\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "\n",
    "# Train model with full data X and y (not X_train and y_train)\n",
    "knn.fit(X, y)\n",
    "\n",
    "# make predictions for out-of-sample data\n",
    "knn.predict([[1,2,3,4], [3,4,2,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsides of train/test split?\n",
    "- Provides a high-variance estimate of out-of-sample accuracy, meaning it can change a lot depending upon \n",
    "  which observations are in the training set vs the testing set\n",
    "- **K-fold cross-validation** largely overcomes this limitation, by repeating the train-test split process multiple times\n",
    "  and averaging over that.\n",
    "- But, train/test split is still useful because of its flexibility and speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
